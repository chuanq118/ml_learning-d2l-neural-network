{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "batch_size = 256\n",
    "# 调用封装好的加载数据集的函数\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST是一个替代MNIST手写数字集的图像数据集。它是由Zalando（一家德国的时尚科技公司）旗下的研究部门提供的。该数据集包含了10个类别的共7万张灰度图像，涵盖了从衣物到鞋子等不同种类的时尚物品。每个类别有7000张图像，其中6000张是训练图像，1000张是测试图像。每张图片的大小为28x28像素12。\n",
    "\n",
    "在PyTorch中，使用torchvision.datasets.FashionMNIST可以方便地读取Fashion-MNIST数据集。如果您使用PyTorch读取Fashion-MNIST数据集，您会发现训练集的tensor shape为[60000, 1, 28, 28]，而测试集的tensor shape为[10000, 1, 28, 28]。因此，您读取到的训练集tensor shape为[256, 1, 28, 28]可能是由于您在读取数据时使用了batch_size=256的参数设置。31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "tensor([6, 5, 3, 0, 1, 1, 7, 0, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "# 分析下数据集\n",
    "for X, y in train_iter:\n",
    "    print(type(X)), print(type(y))\n",
    "    print(X.shape), print(y.shape)\n",
    "    # y 为实际的类型\n",
    "    print(y[range(10)])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建单层的神经网络  \n",
    "将 softmax 作为该层神经网络的激活函数\n",
    "\n",
    "> softmax和sigmoid函数都是神经网络中常用的激活函数。在神经网络中，激活函数通常被放置在每个神经元的输出端，用>于将神经元的输出转换为非线性形式。这样可以使神经网络能够学习非线性关系，从而提高模型的表达能力1。  \n",
    "> sigmoid函数是一种常用的激活函数，它将输入值映射到0到1之间的值。在二分类问题中，sigmoid函数通常被用于输出层，将输出值转换为0到1之间的概率值。在多标签分类问题中，sigmoid函数也可以被用于输出层，将输出值转换为0到1之间的概率值2.  \n",
    "> softmax函数是一种常用的激活函数，它将输入值映射到0到1之间的值，并且所有输出值的和为1。在多分类问题中，softmax函数通常被用于输出层，将输出值转换为0到1之间的概率值，并且所有输出概率之和为13.  \n",
    "因此，在神经网络中，sigmoid函数通常被用于二分类或多标签分类问题中，而softmax函数通常被用于多分类问题中。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，nn.CrossEntropyLoss() 函数是用于计算交叉熵损失的函数。其中 reduction 参数用于控制输出损失的形式。当 reduction=‘none’ 时，函数会输出一个形状为 (batch_size, num_classes) 的矩阵，表示每个样本的每个类别的损失1。\n",
    "\n",
    "换句话说，当 reduction=‘none’ 时，函数不会对每个样本的损失进行求和或平均，而是返回一个形状为 (batch_size, num_classes) 的矩阵，其中每个元素表示该样本在该类别上的损失值1。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    z = <\\vec X, \\vec W> + b\n",
    "$$\n",
    "\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla f(\\theta_t)$$\n",
    "> 其中，θt​ 表示第 t 次迭代的参数，η 表示学习率，∇f(θt​) 表示损失函数在 θt​ 处的梯度\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\mathbf{X})_{ij} = \\frac{\\exp(\\mathbf{X}_{ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD  \n",
    "SGD 是随机梯度下降（stochastic gradient descent）的缩写。它是一种常用的优化算法，用于训练神经网络模型。在每次迭代中，SGD 会随机选择一部分样本来计算梯度，并使用这些梯度来更新模型的参数。由于每次迭代中只使用了一部分样本，因此 SGD 的计算速度比全批量梯度下降（batch gradient descent）快得多。但是，由于 SGD 只使用了一部分样本，因此它的梯度估计可能会存在噪声，从而导致模型训练过程中出现震荡1。\n",
    "\n",
    "##### net parameters  \n",
    "在 PyTorch 中，net.parameters() 是一个函数，它返回一个包含模型所有参数的迭代器。这些参数可以用于优化器的更新操作，例如 SGD、Adam 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001CBE82EAAC0>\n"
     ]
    }
   ],
   "source": [
    "# 添加一层 输入向量 784 个参数 输出向量 10 个类别\n",
    "neural_network = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "# 初始化权重\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "neural_network.apply(init_weights);\n",
    "\n",
    "# 梯度下降的优化算法\n",
    "gradient_decent = torch.optim.SGD(neural_network.parameters(), lr=0.1)\n",
    "\n",
    "print(neural_network.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[重新审视 Softmax 的实现](https://zh-v2.d2l.ai/chapter_linear-networks/softmax-regression-concise.html#id3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们使用softmax函数时，我们通常会将一个向量作为输入。例如，假设我们有一个大小为4的向量[1.0, 2.0, 3.0, 4.0]，我们想将其转换为概率分布。我们可以使用softmax函数来实现这一点。softmax函数的输出是一个概率分布，其中每个元素都是非负的，并且所有元素的和为1。在这个例子中，softmax函数的输出将是[0.0321, 0.0871, 0.2369, 0.6439]。\n",
    "\n",
    "在计算softmax时，如果向量中的一些数值非常大，那么exp(向量中的数值)可能大于数据类型容许的最大数字，即上溢（overflow）。这将使分母或分子变为inf（无穷大），最后得到的是0、inf或nan（不是数字）的概率分布。为了解决这个问题，我们可以在继续softmax计算之前，先从所有向量中减去max(向量)。在这个例子中，max([1.0, 2.0, 3.0, 4.0]) = 4.0。因此，在计算softmax之前，我们将每个元素减去4.0。这样做不会改变softmax的返回值，但可以避免上溢。在减法和规范化步骤之后，可能有些元素具有较大的负值。由于精度受限，exp(这些负值)将有接近零的值，即下溢（underflow）。这些值可能会四舍五入为零，使得概率分布为零，并且使得log(概率分布)的值为-inf。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵损失函数 -> \n",
    "# 注意使用 reduction='none' 来使 log 和 softmax 的 e 进行抵消\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PyTorch中，neural_network.train()是用来将神经网络模型设置为训练模式的。在训练模式下，神经网络会更新权重和偏差，以便更好地拟合训练数据。此外，在训练模式下，一些层（如Dropout和BatchNorm）会表现出不同的行为。例如，在训练模式下，BatchNorm会在每个新批次上更新移动平均值；而在评估模式下，这些更新会被冻结。1\n",
    "\n",
    "当你完成训练时，你可以使用neural_network.eval()将神经网络模型设置为评估模式。在评估模式下，神经网络不会更新权重和偏差，并且所有层都会表现出相同的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终平均预测率 -> 0.8533188700675964\n",
      "最终平均预测率 -> 0.8533521294593811\n",
      "最终平均预测率 -> 0.8552250266075134\n",
      "最终平均预测率 -> 0.854327380657196\n",
      "最终平均预测率 -> 0.8561502695083618\n",
      "最终平均预测率 -> 0.8564550280570984\n",
      "最终平均预测率 -> 0.8577404022216797\n",
      "最终平均预测率 -> 0.8570090532302856\n",
      "最终平均预测率 -> 0.8576020002365112\n",
      "最终平均预测率 -> 0.8587377667427063\n",
      "最终平均预测率 -> 0.8593916296958923\n",
      "最终平均预测率 -> 0.8580784797668457\n",
      "最终平均预测率 -> 0.8599511981010437\n",
      "最终平均预测率 -> 0.8605053424835205\n",
      "最终平均预测率 -> 0.8601452112197876\n",
      "最终平均预测率 -> 0.8594969511032104\n",
      "最终平均预测率 -> 0.8606881499290466\n",
      "最终平均预测率 -> 0.8611259460449219\n",
      "最终平均预测率 -> 0.861358642578125\n",
      "最终平均预测率 -> 0.8618128895759583\n",
      "最终平均预测率 -> 0.8623005151748657\n",
      "最终平均预测率 -> 0.8623393774032593\n",
      "最终平均预测率 -> 0.8624224662780762\n",
      "最终平均预测率 -> 0.8622395992279053\n",
      "最终平均预测率 -> 0.8627936244010925\n",
      "最终平均预测率 -> 0.8620401620864868\n",
      "最终平均预测率 -> 0.8626053333282471\n",
      "最终平均预测率 -> 0.8626219630241394\n",
      "最终平均预测率 -> 0.8629986643791199\n",
      "最终平均预测率 -> 0.8636912107467651\n",
      "最终平均预测率 -> 0.8631260395050049\n",
      "最终平均预测率 -> 0.8643174171447754\n",
      "最终平均预测率 -> 0.8639517426490784\n",
      "最终平均预测率 -> 0.8635582327842712\n",
      "最终平均预测率 -> 0.8645445704460144\n",
      "最终平均预测率 -> 0.863824188709259\n",
      "最终平均预测率 -> 0.8642619848251343\n",
      "最终平均预测率 -> 0.8649158477783203\n",
      "最终平均预测率 -> 0.8645888566970825\n",
      "最终平均预测率 -> 0.8644614219665527\n",
      "最终平均预测率 -> 0.8656526803970337\n",
      "最终平均预测率 -> 0.8646054267883301\n",
      "最终平均预测率 -> 0.8658743500709534\n",
      "最终平均预测率 -> 0.86539226770401\n",
      "最终平均预测率 -> 0.8654531836509705\n",
      "最终平均预测率 -> 0.8655807375907898\n",
      "最终平均预测率 -> 0.8662123680114746\n",
      "最终平均预测率 -> 0.8659297823905945\n",
      "最终平均预测率 -> 0.8648713827133179\n",
      "最终平均预测率 -> 0.8667609095573425\n",
      "最终平均预测率 -> 0.8658354878425598\n",
      "最终平均预测率 -> 0.8661513328552246\n",
      "最终平均预测率 -> 0.8666279315948486\n",
      "最终平均预测率 -> 0.8659408092498779\n",
      "最终平均预测率 -> 0.8661070466041565\n",
      "最终平均预测率 -> 0.8664893507957458\n",
      "最终平均预测率 -> 0.8664118051528931\n",
      "最终平均预测率 -> 0.8665170073509216\n",
      "最终平均预测率 -> 0.8669714331626892\n",
      "最终平均预测率 -> 0.8668107986450195\n",
      "最终平均预测率 -> 0.8669548034667969\n",
      "最终平均预测率 -> 0.8673481345176697\n",
      "最终平均预测率 -> 0.8674035668373108\n",
      "最终平均预测率 -> 0.8680574297904968\n",
      "最终平均预测率 -> 0.8668328523635864\n",
      "最终平均预测率 -> 0.8668439984321594\n",
      "最终平均预测率 -> 0.8681460022926331\n",
      "最终平均预测率 -> 0.8677360415458679\n",
      "最终平均预测率 -> 0.8682735562324524\n",
      "最终平均预测率 -> 0.8677194118499756\n",
      "最终平均预测率 -> 0.8677582144737244\n",
      "最终平均预测率 -> 0.8673260807991028\n",
      "最终平均预测率 -> 0.8673260807991028\n",
      "最终平均预测率 -> 0.8675365447998047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m      2\u001b[0m     collector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty(\u001b[39m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m train_iter:\n\u001b[0;32m      4\u001b[0m         \u001b[39m# 计算损失\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         y_hat \u001b[39m=\u001b[39m neural_network(X)\n\u001b[0;32m      6\u001b[0m         _, y_predict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(y_hat, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\multiprocessing\\queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    880\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\legen\\local\\anaconda\\envs\\d2l-zh\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    812\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    collector = torch.empty(0)\n",
    "    for X, y in train_iter:\n",
    "        # 计算损失\n",
    "        y_hat = neural_network(X)\n",
    "        _, y_predict = torch.max(y_hat, dim=1) \n",
    "        right_counter = 0\n",
    "        for i in range(y_predict.shape[0]):\n",
    "            if y_predict[i].item() == y[i].item():\n",
    "                right_counter += 1\n",
    "        collector = torch.cat((collector, torch.tensor([right_counter / y_predict.shape[0]])))\n",
    "        l = loss(y_hat, y)\n",
    "        # 梯度清零\n",
    "        gradient_decent.zero_grad()\n",
    "        # 反向传播\n",
    "        lm = l.mean()\n",
    "        # print(lm)\n",
    "        lm.backward()\n",
    "        # 更新参数\n",
    "        gradient_decent.step()\n",
    "    print(f'平均预测率 -> {collector.mean()}')\n",
    "# for name, param in neural_network.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         if name == '1.bias':\n",
    "#             print(name, param.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b320c748c085e173cc38d9117a1564438f46235551c4648d4648ac8881850d65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
